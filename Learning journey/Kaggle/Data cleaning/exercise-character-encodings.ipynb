{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/character-encodings).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"In this exercise, you'll apply what you learned in the **Character encodings** tutorial.\n\n# Setup\n\nThe questions below will give you feedback on your work. Run the following cell to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"from learntools.core import binder\nbinder.bind(globals())\nfrom learntools.data_cleaning.ex4 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:10.642206Z","iopub.execute_input":"2022-09-08T04:01:10.642661Z","iopub.status.idle":"2022-09-08T04:01:10.651025Z","shell.execute_reply.started":"2022-09-08T04:01:10.642620Z","shell.execute_reply":"2022-09-08T04:01:10.649060Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# Get our environment set up\n\nThe first thing we'll need to do is load in the libraries we'll be using.","metadata":{}},{"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# helpful character encoding module\nimport chardet\n\n# set seed for reproducibility\nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:10.653104Z","iopub.execute_input":"2022-09-08T04:01:10.653776Z","iopub.status.idle":"2022-09-08T04:01:10.661675Z","shell.execute_reply.started":"2022-09-08T04:01:10.653694Z","shell.execute_reply":"2022-09-08T04:01:10.660550Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# 1) What are encodings?\n\nYou're working with a dataset composed of bytes.  Run the code cell below to print a sample entry.","metadata":{}},{"cell_type":"code","source":"sample_entry = b'\\xa7A\\xa6n'\nprint(sample_entry)\nprint('data type:', type(sample_entry))","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:10.663528Z","iopub.execute_input":"2022-09-08T04:01:10.664756Z","iopub.status.idle":"2022-09-08T04:01:10.676574Z","shell.execute_reply.started":"2022-09-08T04:01:10.664718Z","shell.execute_reply":"2022-09-08T04:01:10.675350Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"You notice that it doesn't use the standard UTF-8 encoding. \n\nUse the next code cell to create a variable `new_entry` that changes the encoding from `\"big5-tw\"` to `\"utf-8\"`.  `new_entry` should have the bytes datatype.","metadata":{}},{"cell_type":"code","source":"new_entry = sample_entry.decode(encoding='big5-tw').encode('UTF-8',errors='replace')\n\n# Check your answer\nq1.check()","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:10.678879Z","iopub.execute_input":"2022-09-08T04:01:10.679755Z","iopub.status.idle":"2022-09-08T04:01:10.693951Z","shell.execute_reply.started":"2022-09-08T04:01:10.679706Z","shell.execute_reply":"2022-09-08T04:01:10.692693Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q1.hint()\n#q1.solution()","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:10.696640Z","iopub.execute_input":"2022-09-08T04:01:10.697630Z","iopub.status.idle":"2022-09-08T04:01:10.702687Z","shell.execute_reply.started":"2022-09-08T04:01:10.697596Z","shell.execute_reply":"2022-09-08T04:01:10.701419Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# 2) Reading in files with encoding problems\n\nUse the code cell below to read in this file at path `\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\"`.  \n\nFigure out what the correct encoding should be and read in the file to a DataFrame `police_killings`.","metadata":{}},{"cell_type":"code","source":"with open('../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv','rb') as rawdata:\n    result = chardet.detect(rawdata.read(30000))\nresult","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:10.704389Z","iopub.execute_input":"2022-09-08T04:01:10.705079Z","iopub.status.idle":"2022-09-08T04:01:11.385939Z","shell.execute_reply.started":"2022-09-08T04:01:10.705044Z","shell.execute_reply":"2022-09-08T04:01:11.384323Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"police_killings = pd.read_csv('../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv',encoding = 'Windows-1252')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:11.388074Z","iopub.execute_input":"2022-09-08T04:01:11.389230Z","iopub.status.idle":"2022-09-08T04:01:11.429292Z","shell.execute_reply.started":"2022-09-08T04:01:11.389185Z","shell.execute_reply":"2022-09-08T04:01:11.427765Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"\n# Check your answer\nq2.check()","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:11.431076Z","iopub.execute_input":"2022-09-08T04:01:11.431465Z","iopub.status.idle":"2022-09-08T04:01:11.443046Z","shell.execute_reply.started":"2022-09-08T04:01:11.431432Z","shell.execute_reply":"2022-09-08T04:01:11.441899Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Feel free to use any additional code cells for supplemental work.  To get credit for finishing this question, you'll need to run `q2.check()` and get a result of **Correct**.","metadata":{}},{"cell_type":"code","source":"# (Optional) Use this code cell for any additional work.","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:11.444455Z","iopub.execute_input":"2022-09-08T04:01:11.445053Z","iopub.status.idle":"2022-09-08T04:01:11.451853Z","shell.execute_reply.started":"2022-09-08T04:01:11.445019Z","shell.execute_reply":"2022-09-08T04:01:11.450225Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q2.hint()\n#q2.solution()","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:11.453688Z","iopub.execute_input":"2022-09-08T04:01:11.454917Z","iopub.status.idle":"2022-09-08T04:01:11.462053Z","shell.execute_reply.started":"2022-09-08T04:01:11.454839Z","shell.execute_reply":"2022-09-08T04:01:11.460736Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# 3) Saving your files with UTF-8 encoding\n\nSave a version of the police killings dataset to CSV with UTF-8 encoding.  Your answer will be marked correct after saving this file.  \n\nNote: When using the `to_csv()` method, supply only the name of the file (e.g., `\"my_file.csv\"`).  This saves the file at the filepath `\"/kaggle/working/my_file.csv\"`.","metadata":{}},{"cell_type":"code","source":"# TODO: Save the police killings dataset to CSV\npolice_killings.to_csv(\"/kaggle/working/my_file.csv\")\n\n# Check your answer\nq3.check()","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:11.465104Z","iopub.execute_input":"2022-09-08T04:01:11.465721Z","iopub.status.idle":"2022-09-08T04:01:11.508797Z","shell.execute_reply.started":"2022-09-08T04:01:11.465580Z","shell.execute_reply":"2022-09-08T04:01:11.507166Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q3.hint()\n#q3.solution()","metadata":{"execution":{"iopub.status.busy":"2022-09-08T04:01:11.510765Z","iopub.execute_input":"2022-09-08T04:01:11.511737Z","iopub.status.idle":"2022-09-08T04:01:11.517386Z","shell.execute_reply.started":"2022-09-08T04:01:11.511683Z","shell.execute_reply":"2022-09-08T04:01:11.516103Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# (Optional) More practice\n\nCheck out [this dataset of files in different character encodings](https://www.kaggle.com/rtatman/character-encoding-examples). Can you read in all the files with their original encodings and them save them out as UTF-8 files?\n\nIf you have a file that's in UTF-8 but has just a couple of weird-looking characters in it, you can try out the [ftfy module](https://ftfy.readthedocs.io/en/latest/#) and see if it helps. \n\n# Keep going\n\nIn the final lesson, learn how to [**clean up inconsistent text entries**](https://www.kaggle.com/alexisbcook/inconsistent-data-entry) in your dataset.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*","metadata":{}}]}